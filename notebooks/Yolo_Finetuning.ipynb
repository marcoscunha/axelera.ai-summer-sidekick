{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b865556",
   "metadata": {},
   "source": [
    "# YOLOv11m Finetuning Script\n",
    "This notebook demonstrates how to finetune the YOLOv11m model using your custom dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "586701e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages (if needed)\n",
    "# !pip install ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "293bcd23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bb4633ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to your merged dataset\n",
    "DATASET_PATH = '../datasets/training/yolo_finetuning'\n",
    "MODEL_NAME = \"yolo11n\"\n",
    "\n",
    "# Path to YOLOv11m pretrained weights\n",
    "PRETRAINED_WEIGHTS = f\"{MODEL_NAME}.pt\"  # Update with actual path if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d69e7f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model\n",
    "model = YOLO(PRETRAINED_WEIGHTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b92680de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.3.185 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.182 ðŸš€ Python-3.10.6 torch-1.13.1+cu117 CUDA:0 (NVIDIA GeForce RTX 3050 Ti Laptop GPU, 3771MiB)\n",
      "WARNING âš ï¸ Upgrade to torch>=2.0.0 for deterministic training.\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=20, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=../datasets/training/yolo_finetuning/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=100, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=10, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.001, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolo11n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=yolo11n_bowl_fountain_finetune, nbs=64, nms=False, opset=None, optimize=False, optimizer=Adam, overlap_mask=True, patience=10, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=runs, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=runs/yolo11n_bowl_fountain_finetune, save_frames=False, save_json=False, save_period=10, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=82\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
      "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
      "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      "  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    111296  ultralytics.nn.modules.block.C3k2            [384, 128, 1, False]          \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1     32096  ultralytics.nn.modules.block.C3k2            [256, 64, 1, False]           \n",
      " 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1     86720  ultralytics.nn.modules.block.C3k2            [192, 128, 1, False]          \n",
      " 20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n",
      " 23        [16, 19, 22]  1    467848  ultralytics.nn.modules.head.Detect           [82, [64, 128, 256]]          \n",
      "YOLO11n summary: 181 layers, 2,627,016 parameters, 2,627,000 gradients, 6.6 GFLOPs\n",
      "\n",
      "Transferred 448/499 items from pretrained weights\n",
      "Freezing layer 'model.0.conv.weight'\n",
      "Freezing layer 'model.0.bn.weight'\n",
      "Freezing layer 'model.0.bn.bias'\n",
      "Freezing layer 'model.1.conv.weight'\n",
      "Freezing layer 'model.1.bn.weight'\n",
      "Freezing layer 'model.1.bn.bias'\n",
      "Freezing layer 'model.2.cv1.conv.weight'\n",
      "Freezing layer 'model.2.cv1.bn.weight'\n",
      "Freezing layer 'model.2.cv1.bn.bias'\n",
      "Freezing layer 'model.2.cv2.conv.weight'\n",
      "Freezing layer 'model.2.cv2.bn.weight'\n",
      "Freezing layer 'model.2.cv2.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.3.conv.weight'\n",
      "Freezing layer 'model.3.bn.weight'\n",
      "Freezing layer 'model.3.bn.bias'\n",
      "Freezing layer 'model.4.cv1.conv.weight'\n",
      "Freezing layer 'model.4.cv1.bn.weight'\n",
      "Freezing layer 'model.4.cv1.bn.bias'\n",
      "Freezing layer 'model.4.cv2.conv.weight'\n",
      "Freezing layer 'model.4.cv2.bn.weight'\n",
      "Freezing layer 'model.4.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.5.conv.weight'\n",
      "Freezing layer 'model.5.bn.weight'\n",
      "Freezing layer 'model.5.bn.bias'\n",
      "Freezing layer 'model.6.cv1.conv.weight'\n",
      "Freezing layer 'model.6.cv1.bn.weight'\n",
      "Freezing layer 'model.6.cv1.bn.bias'\n",
      "Freezing layer 'model.6.cv2.conv.weight'\n",
      "Freezing layer 'model.6.cv2.bn.weight'\n",
      "Freezing layer 'model.6.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv3.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv3.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv3.bn.bias'\n",
      "Freezing layer 'model.6.m.0.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.0.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.0.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.0.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.0.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.0.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.0.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.0.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.0.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.0.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.0.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.0.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.7.conv.weight'\n",
      "Freezing layer 'model.7.bn.weight'\n",
      "Freezing layer 'model.7.bn.bias'\n",
      "Freezing layer 'model.8.cv1.conv.weight'\n",
      "Freezing layer 'model.8.cv1.bn.weight'\n",
      "Freezing layer 'model.8.cv1.bn.bias'\n",
      "Freezing layer 'model.8.cv2.conv.weight'\n",
      "Freezing layer 'model.8.cv2.bn.weight'\n",
      "Freezing layer 'model.8.cv2.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv3.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv3.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv3.bn.bias'\n",
      "Freezing layer 'model.8.m.0.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.8.m.0.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.8.m.0.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.8.m.0.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.8.m.0.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.8.m.0.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.9.cv1.conv.weight'\n",
      "Freezing layer 'model.9.cv1.bn.weight'\n",
      "Freezing layer 'model.9.cv1.bn.bias'\n",
      "Freezing layer 'model.9.cv2.conv.weight'\n",
      "Freezing layer 'model.9.cv2.bn.weight'\n",
      "Freezing layer 'model.9.cv2.bn.bias'\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 4586.1Â±2070.0 MB/s, size: 704.0 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/mcunha/devel/marcoscunha/axelera.ai/axelera.ai-summer-sidekick/datasets/training/yolo_finetuning/train/labels... 1809 images, 0 backgroun\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /home/mcunha/devel/marcoscunha/axelera.ai/axelera.ai-summer-sidekick/datasets/training/yolo_finetuning/train/labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 1951.7Â±1501.5 MB/s, size: 79.2 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/mcunha/devel/marcoscunha/axelera.ai/axelera.ai-summer-sidekick/datasets/training/yolo_finetuning/val/labels.cache... 389 images, 0 backgrou\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/yolo11n_bowl_fountain_finetune/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m Adam(lr=0.001, momentum=0.937) with parameter groups 81 weight(decay=0.0), 88 weight(decay=0.00046875), 87 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns/yolo11n_bowl_fountain_finetune\u001b[0m\n",
      "Starting training for 100 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      1/100      2.58G      1.277      3.446      1.315         92        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 91/91 [00:17<00:00,  5.17it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:02<00:00,  4.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        389       3086      0.047      0.176      0.105     0.0746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      2/100      2.53G      1.319      2.473       1.35         98        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 91/91 [00:16<00:00,  5.43it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:02<00:00,  4.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        389       3086      0.526      0.202      0.198      0.132\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      3/100      2.28G      1.338      2.125      1.382         71        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 91/91 [00:16<00:00,  5.47it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:02<00:00,  4.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        389       3086      0.521      0.239      0.233      0.148\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      4/100      2.88G      1.365       1.97      1.394         64        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 91/91 [00:16<00:00,  5.41it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:02<00:00,  4.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        389       3086      0.532      0.243      0.267      0.176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      5/100      2.86G      1.333      1.872      1.375        133        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 91/91 [00:16<00:00,  5.43it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:02<00:00,  4.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        389       3086      0.405      0.299      0.264      0.184\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      6/100      2.79G      1.308      1.794      1.362         88        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 91/91 [00:16<00:00,  5.41it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:02<00:00,  4.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        389       3086      0.504      0.266      0.283      0.181\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      7/100      2.66G      1.298      1.744      1.352         79        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 91/91 [00:16<00:00,  5.39it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:02<00:00,  4.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        389       3086      0.513      0.291      0.289      0.195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      8/100      2.11G      1.271      1.678      1.334        100        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 91/91 [00:16<00:00,  5.44it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:02<00:00,  4.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        389       3086      0.487      0.304      0.327      0.221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      9/100      2.52G      1.273      1.632      1.333        131        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 91/91 [00:16<00:00,  5.44it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:02<00:00,  4.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        389       3086      0.475      0.308      0.301      0.196\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     10/100      2.73G      1.261      1.578      1.326        113        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 91/91 [00:16<00:00,  5.39it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:02<00:00,  4.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        389       3086      0.529      0.305       0.33      0.215\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     11/100      2.32G      1.246      1.574      1.327        206        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 91/91 [00:16<00:00,  5.44it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:02<00:00,  4.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        389       3086      0.501      0.294      0.327      0.217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     12/100       2.6G      1.228      1.541       1.31         67        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 91/91 [00:16<00:00,  5.45it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:02<00:00,  4.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        389       3086      0.528      0.311       0.34      0.227\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     13/100      2.73G      1.225        1.5      1.304        121        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 91/91 [00:16<00:00,  5.40it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:02<00:00,  4.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        389       3086      0.503      0.313      0.338       0.23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     14/100      2.89G       1.22      1.495      1.299         81        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 91/91 [00:16<00:00,  5.40it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:02<00:00,  4.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        389       3086       0.49      0.325      0.334       0.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     15/100       2.7G      1.209      1.466      1.293         75        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 91/91 [00:16<00:00,  5.42it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:02<00:00,  4.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        389       3086      0.572      0.279      0.313      0.215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     16/100      2.08G      1.196      1.437       1.29         76        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 91/91 [00:16<00:00,  5.39it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:02<00:00,  4.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        389       3086      0.571      0.299      0.331      0.222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     17/100      2.58G      1.194      1.414      1.276        148        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 91/91 [00:16<00:00,  5.38it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:02<00:00,  4.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        389       3086      0.544      0.293       0.33       0.22\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     18/100      2.94G      1.182      1.401      1.268        133        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 91/91 [00:16<00:00,  5.36it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:02<00:00,  4.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        389       3086       0.45      0.338      0.341      0.226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     19/100      2.27G      1.173       1.38      1.266        127        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 91/91 [00:16<00:00,  5.40it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:02<00:00,  4.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        389       3086      0.534      0.319      0.353      0.235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     20/100      2.49G      1.169      1.358      1.263         92        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 91/91 [00:16<00:00,  5.38it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:02<00:00,  4.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        389       3086      0.474       0.36      0.351       0.24\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     21/100      2.76G      1.173      1.363      1.262        141        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 91/91 [00:16<00:00,  5.39it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:02<00:00,  4.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        389       3086      0.512      0.328      0.341      0.218\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     22/100      2.53G      1.155      1.331      1.258         73        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 91/91 [00:16<00:00,  5.40it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:02<00:00,  4.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        389       3086      0.605        0.3      0.346      0.226\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     23/100      2.24G       1.16      1.344      1.256        100        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 91/91 [00:16<00:00,  5.37it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:02<00:00,  4.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        389       3086      0.532      0.328      0.343      0.233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     24/100      2.78G      1.152      1.313      1.245        104        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 91/91 [00:16<00:00,  5.38it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:02<00:00,  4.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        389       3086      0.572      0.312      0.348      0.227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     25/100       2.8G      1.128      1.285      1.235         95        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 91/91 [00:16<00:00,  5.38it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:02<00:00,  4.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        389       3086      0.443      0.353      0.341      0.223\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     26/100       2.5G      1.136      1.296      1.237         62        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 91/91 [00:16<00:00,  5.41it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:02<00:00,  4.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        389       3086      0.509      0.332      0.342      0.225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     27/100      2.35G      1.129      1.264      1.232        150        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 91/91 [00:16<00:00,  5.40it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:02<00:00,  4.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        389       3086      0.565        0.3      0.331      0.223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     28/100      2.15G      1.127      1.268       1.23        129        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 91/91 [00:16<00:00,  5.39it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:02<00:00,  4.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        389       3086      0.565      0.315      0.347      0.229\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     29/100      2.44G      1.128      1.247      1.229         90        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 91/91 [00:16<00:00,  5.41it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:02<00:00,  4.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        389       3086      0.491      0.322      0.333      0.219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     30/100      2.39G      1.125      1.234       1.22        122        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 91/91 [00:16<00:00,  5.39it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:02<00:00,  4.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        389       3086       0.59      0.293      0.347      0.234\n",
      "\u001b[34m\u001b[1mEarlyStopping: \u001b[0mTraining stopped early as no improvement observed in last 10 epochs. Best results observed at epoch 20, best model saved as best.pt.\n",
      "To update EarlyStopping(patience=10) pass a new patience value, i.e. `patience=300` or use `patience=0` to disable EarlyStopping.\n",
      "\n",
      "30 epochs completed in 0.162 hours.\n",
      "Optimizer stripped from runs/yolo11n_bowl_fountain_finetune/weights/last.pt, 5.5MB\n",
      "Optimizer stripped from runs/yolo11n_bowl_fountain_finetune/weights/best.pt, 5.5MB\n",
      "\n",
      "Validating runs/yolo11n_bowl_fountain_finetune/weights/best.pt...\n",
      "Ultralytics 8.3.182 ðŸš€ Python-3.10.6 torch-1.13.1+cu117 CUDA:0 (NVIDIA GeForce RTX 3050 Ti Laptop GPU, 3771MiB)\n",
      "YOLO11n summary (fused): 100 layers, 2,619,166 parameters, 0 gradients, 6.5 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:02<00:00,  4.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        389       3086        0.5      0.341      0.351       0.24\n",
      "                person         98        314      0.492      0.713       0.68      0.435\n",
      "               bicycle          9         13      0.344      0.308      0.163     0.0974\n",
      "                   car         23         64       0.63      0.625      0.609      0.407\n",
      "            motorcycle          5          8      0.561      0.625       0.61      0.389\n",
      "                   bus          1          1      0.346          1      0.995      0.995\n",
      "                 truck          4          5      0.377        0.4       0.34      0.135\n",
      "                  boat          2          6          0          0     0.0222    0.00444\n",
      "         traffic light          4         14      0.323      0.286      0.345      0.214\n",
      "          fire hydrant          4          4      0.411        0.5      0.478      0.318\n",
      "             stop sign          2          2          1          0          0          0\n",
      "         parking meter          2          2      0.826        0.5      0.499      0.399\n",
      "                 bench         19         23      0.392      0.348      0.342      0.231\n",
      "                  bird          8         11      0.661      0.179      0.199      0.129\n",
      "                   cat        184        202      0.683      0.881      0.878      0.617\n",
      "                   dog         17         20      0.437       0.35      0.338      0.184\n",
      "                 horse          3          3      0.351      0.667      0.789      0.584\n",
      "                   cow          1          1          1          0      0.995      0.895\n",
      "               giraffe          1          1      0.579          1      0.995      0.895\n",
      "              backpack          9         14      0.528      0.357      0.348      0.164\n",
      "              umbrella          8         13      0.495      0.538      0.488      0.293\n",
      "               handbag         14         24     0.0997      0.125     0.0619     0.0371\n",
      "                   tie          4          4      0.253        0.5      0.172      0.105\n",
      "              suitcase          8         14      0.328      0.357      0.359      0.206\n",
      "               frisbee          1          1          1          0          0          0\n",
      "           sports ball          4          5          1          0      0.104     0.0728\n",
      "          baseball bat          1          1          1          0          0          0\n",
      "        baseball glove          1          1          0          0          0          0\n",
      "             surfboard          1          1          0          0          0          0\n",
      "                bottle         47        133      0.311      0.323      0.291      0.163\n",
      "            wine glass         14         50      0.395       0.08      0.108     0.0557\n",
      "                   cup         48        114      0.361      0.298      0.282      0.177\n",
      "                  fork          8         12          0          0    0.00554    0.00282\n",
      "                 knife         13         39      0.118     0.0256      0.029     0.0151\n",
      "                 spoon         12         31          1          0    0.00286    0.00143\n",
      "                  bowl         32         75       0.52      0.361      0.344      0.199\n",
      "                banana          7         13      0.144     0.0769     0.0469     0.0397\n",
      "                 apple          9         18     0.0447     0.0556     0.0458     0.0197\n",
      "              sandwich          2          2          0          0          0          0\n",
      "                orange          7         29      0.182      0.138      0.179     0.0987\n",
      "              broccoli          1          2          1      0.927      0.995      0.527\n",
      "                carrot          2          2          1          0          0          0\n",
      "               hot dog          2          2      0.562        0.5      0.695      0.487\n",
      "                 pizza          6          9        0.5      0.556      0.585      0.317\n",
      "                 donut          2         10          0          0     0.0389     0.0247\n",
      "                  cake          5         16      0.381      0.188      0.267      0.132\n",
      "                 chair        100        315      0.545      0.321      0.346      0.207\n",
      "                 couch         60         89      0.556      0.605      0.553      0.414\n",
      "          potted plant        172        342      0.387      0.544      0.464      0.251\n",
      "                   bed         35         36      0.483      0.556      0.563      0.376\n",
      "          dining table         64         99       0.43      0.253      0.244      0.116\n",
      "                toilet         17         20      0.473       0.45      0.488      0.356\n",
      "                    tv         55         68      0.632      0.691      0.689      0.474\n",
      "                laptop         36         39      0.474      0.641      0.604      0.361\n",
      "                 mouse         13         14       0.39      0.357        0.3      0.203\n",
      "                remote         29         51      0.296     0.0784      0.128     0.0743\n",
      "              keyboard         16         22        0.5      0.364      0.327      0.179\n",
      "            cell phone         16         17      0.203      0.118     0.0546     0.0369\n",
      "             microwave         11         11      0.893      0.455      0.572      0.378\n",
      "                  oven         20         26      0.811      0.462      0.511      0.267\n",
      "               toaster          1          1          1          0          0          0\n",
      "                  sink         31         35      0.218      0.343      0.195      0.131\n",
      "          refrigerator         19         20      0.481        0.5      0.556      0.385\n",
      "                  book         57        345      0.288      0.209      0.149     0.0551\n",
      "                 clock         15         16      0.447      0.438       0.41      0.254\n",
      "                  vase         52         94      0.567      0.277      0.304      0.173\n",
      "              scissors          4          5          1          0          0          0\n",
      "            teddy bear         11         18      0.542      0.444      0.424      0.268\n",
      "            toothbrush          3          3          1          0    0.00328    0.00262\n",
      "           custom_bowl         34         34      0.879          1      0.976      0.859\n",
      "   custom_pet_fountain         37         37      0.892          1      0.989      0.901\n",
      "Speed: 0.4ms preprocess, 2.5ms inference, 0.0ms loss, 0.6ms postprocess per image\n",
      "Results saved to \u001b[1mruns/yolo11n_bowl_fountain_finetune\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Train/finetune YOLO model\n",
    "results = model.train(\n",
    "    data=f'{DATASET_PATH}/data.yaml',  # Path to your data.yaml\n",
    "    epochs=100,\n",
    "    imgsz=640,\n",
    "    batch=20,\n",
    "    optimizer='Adam',\n",
    "    lr0=0.001,\n",
    "    device='0',  # Use GPU if available, else 'cpu'\n",
    "    project='runs',\n",
    "    save=True,\n",
    "    save_period=10,\n",
    "    name=f\"{MODEL_NAME}_bowl_fountain_finetune\",\n",
    "    exist_ok=True,\n",
    "    resume=False,\n",
    "    freeze=10,\n",
    "    patience=10\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a667ba3b",
   "metadata": {},
   "source": [
    "## Notes\n",
    "- Make sure your `data.yaml` file is correctly set up in the merged dataset folder.\n",
    "- Adjust `epochs`, `batch`, and `imgsz` as needed for your hardware and dataset size.\n",
    "- The finetuned weights will be saved in the `yolo11m_finetune/exp` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ac242c42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.182 ðŸš€ Python-3.10.6 torch-1.13.1+cu117 CPU (11th Gen Intel Core(TM) i7-11800H 2.30GHz)\n",
      "YOLO11n summary (fused): 100 layers, 2,619,166 parameters, 0 gradients, 6.5 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'runs/yolo11n_bowl_fountain_finetune/weights/best.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 86, 8400) (5.3 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.17.0 opset 17...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.65...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success âœ… 1.8s, saved as 'runs/yolo11n_bowl_fountain_finetune/weights/best.onnx' (10.2 MB)\n",
      "\n",
      "Export complete (2.1s)\n",
      "Results saved to \u001b[1m/home/mcunha/devel/marcoscunha/axelera.ai/axelera.ai-summer-sidekick/notebooks/runs/yolo11n_bowl_fountain_finetune/weights\u001b[0m\n",
      "Predict:         yolo predict task=detect model=runs/yolo11n_bowl_fountain_finetune/weights/best.onnx imgsz=640  \n",
      "Validate:        yolo val task=detect model=runs/yolo11n_bowl_fountain_finetune/weights/best.onnx imgsz=640 data=../datasets/training/yolo_finetuning/data.yaml  \n",
      "Visualize:       https://netron.app\n",
      "ONNX model exported to: runs/yolo11n_bowl_fountain_finetune/weights/best.onnx\n"
     ]
    }
   ],
   "source": [
    "# Export the finetuned YOLO model to ONNX format\n",
    "# Replace 'best.pt' with the path to your trained weights if different\n",
    "onnx_path = f\"runs/{MODEL_NAME}_bowl_fountain_finetune/weights/best.onnx\"\n",
    "model.export(format='onnx',\n",
    "             # weights='yolo11m_finetuning/bowl_fountain_finetune/weights/best.pt',\n",
    "             imgsz=640,\n",
    "             dynamic=True,\n",
    "             simplify=True,\n",
    "             half=False,\n",
    "             opset=17,\n",
    "             device='cpu'\n",
    "             # output=onnx_path\n",
    "            )\n",
    "print(f'ONNX model exported to: {onnx_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7b127a22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv\n",
      "Sigmoid\n",
      "Mul\n",
      "Conv\n",
      "Sigmoid\n",
      "Mul\n",
      "Conv\n",
      "Sigmoid\n",
      "Mul\n",
      "Split\n",
      "Conv\n",
      "Sigmoid\n",
      "Mul\n",
      "Conv\n",
      "Sigmoid\n",
      "Mul\n",
      "Add\n",
      "Concat\n",
      "Conv\n",
      "Sigmoid\n",
      "Mul\n",
      "Conv\n",
      "Sigmoid\n",
      "Mul\n",
      "Conv\n",
      "Sigmoid\n",
      "Mul\n",
      "Split\n",
      "Conv\n",
      "Sigmoid\n",
      "Mul\n",
      "Conv\n",
      "Sigmoid\n",
      "Mul\n",
      "Add\n",
      "Concat\n",
      "Conv\n",
      "Sigmoid\n",
      "Mul\n",
      "Conv\n",
      "Sigmoid\n",
      "Mul\n",
      "Conv\n",
      "Sigmoid\n",
      "Mul\n",
      "Split\n",
      "Conv\n",
      "Conv\n",
      "Sigmoid\n",
      "Sigmoid\n",
      "Mul\n",
      "Mul\n",
      "Conv\n",
      "Sigmoid\n",
      "Mul\n",
      "Conv\n",
      "Sigmoid\n",
      "Mul\n",
      "Add\n",
      "Conv\n",
      "Sigmoid\n",
      "Mul\n",
      "Conv\n",
      "Sigmoid\n",
      "Mul\n",
      "Add\n",
      "Concat\n",
      "Conv\n",
      "Sigmoid\n",
      "Mul\n",
      "Concat\n",
      "Conv\n",
      "Sigmoid\n",
      "Mul\n",
      "Conv\n",
      "Sigmoid\n",
      "Mul\n",
      "Conv\n",
      "Sigmoid\n",
      "Mul\n",
      "Split\n",
      "Conv\n",
      "Conv\n",
      "Sigmoid\n",
      "Sigmoid\n",
      "Mul\n",
      "Mul\n",
      "Conv\n",
      "Sigmoid\n",
      "Mul\n",
      "Conv\n",
      "Sigmoid\n",
      "Mul\n",
      "Add\n",
      "Conv\n",
      "Sigmoid\n",
      "Mul\n",
      "Conv\n",
      "Sigmoid\n",
      "Mul\n",
      "Add\n",
      "Concat\n",
      "Conv\n",
      "Sigmoid\n",
      "Mul\n",
      "Concat\n",
      "Conv\n",
      "Sigmoid\n",
      "Mul\n",
      "Conv\n",
      "Sigmoid\n",
      "Mul\n",
      "MaxPool\n",
      "MaxPool\n",
      "MaxPool\n",
      "Concat\n",
      "Conv\n",
      "Sigmoid\n",
      "Mul\n",
      "Conv\n",
      "Sigmoid\n",
      "Mul\n",
      "Split\n",
      "Shape\n",
      "Conv\n",
      "Gather\n",
      "Gather\n",
      "Gather\n",
      "Mul\n",
      "Unsqueeze\n",
      "Unsqueeze\n",
      "Unsqueeze\n",
      "Unsqueeze\n",
      "Concat\n",
      "Concat\n",
      "Reshape\n",
      "Split\n",
      "Transpose\n",
      "Reshape\n",
      "MatMul\n",
      "Conv\n",
      "Mul\n",
      "Softmax\n",
      "Transpose\n",
      "MatMul\n",
      "Reshape\n",
      "Add\n",
      "Conv\n",
      "Add\n",
      "Conv\n",
      "Sigmoid\n",
      "Mul\n",
      "Conv\n",
      "Add\n",
      "Concat\n",
      "Conv\n",
      "Sigmoid\n",
      "Mul\n",
      "Resize\n",
      "Concat\n",
      "Conv\n",
      "Sigmoid\n",
      "Mul\n",
      "Split\n",
      "Conv\n",
      "Sigmoid\n",
      "Mul\n",
      "Conv\n",
      "Sigmoid\n",
      "Mul\n",
      "Add\n",
      "Concat\n",
      "Conv\n",
      "Sigmoid\n",
      "Mul\n",
      "Resize\n",
      "Concat\n",
      "Conv\n",
      "Sigmoid\n",
      "Mul\n",
      "Split\n",
      "Conv\n",
      "Sigmoid\n",
      "Mul\n",
      "Conv\n",
      "Sigmoid\n",
      "Mul\n",
      "Add\n",
      "Concat\n",
      "Conv\n",
      "Sigmoid\n",
      "Mul\n",
      "Conv\n",
      "Conv\n",
      "Conv\n",
      "Sigmoid\n",
      "Sigmoid\n",
      "Sigmoid\n",
      "Mul\n",
      "Mul\n",
      "Mul\n",
      "Concat\n",
      "Conv\n",
      "Conv\n",
      "Conv\n",
      "Sigmoid\n",
      "Sigmoid\n",
      "Sigmoid\n",
      "Mul\n",
      "Mul\n",
      "Mul\n",
      "Conv\n",
      "Conv\n",
      "Split\n",
      "Sigmoid\n",
      "Conv\n",
      "Mul\n",
      "Sigmoid\n",
      "Conv\n",
      "Mul\n",
      "Sigmoid\n",
      "Conv\n",
      "Mul\n",
      "Sigmoid\n",
      "Conv\n",
      "Mul\n",
      "Concat\n",
      "Add\n",
      "Shape\n",
      "Concat\n",
      "Gather\n",
      "Gather\n",
      "Gather\n",
      "Conv\n",
      "Unsqueeze\n",
      "Cast\n",
      "Cast\n",
      "Mul\n",
      "Sigmoid\n",
      "Concat\n",
      "Range\n",
      "Range\n",
      "Unsqueeze\n",
      "Mul\n",
      "Reshape\n",
      "Add\n",
      "Add\n",
      "Concat\n",
      "Conv\n",
      "Conv\n",
      "Conv\n",
      "ConstantOfShape\n",
      "Shape\n",
      "Shape\n",
      "Reshape\n",
      "Reshape\n",
      "Sigmoid\n",
      "Sigmoid\n",
      "Sigmoid\n",
      "Add\n",
      "Concat\n",
      "Mul\n",
      "Mul\n",
      "Mul\n",
      "Expand\n",
      "Expand\n",
      "Concat\n",
      "Conv\n",
      "Conv\n",
      "Unsqueeze\n",
      "Unsqueeze\n",
      "Conv\n",
      "Sigmoid\n",
      "Sigmoid\n",
      "Concat\n",
      "Sigmoid\n",
      "Mul\n",
      "Mul\n",
      "Reshape\n",
      "Mul\n",
      "Conv\n",
      "Conv\n",
      "Split\n",
      "Sigmoid\n",
      "Conv\n",
      "Conv\n",
      "Mul\n",
      "Sigmoid\n",
      "Sigmoid\n",
      "Conv\n",
      "Mul\n",
      "Mul\n",
      "Sigmoid\n",
      "Conv\n",
      "Mul\n",
      "Sigmoid\n",
      "Conv\n",
      "Mul\n",
      "Concat\n",
      "Conv\n",
      "Reshape\n",
      "Shape\n",
      "Sigmoid\n",
      "Gather\n",
      "Gather\n",
      "Mul\n",
      "Cast\n",
      "Cast\n",
      "Mul\n",
      "Add\n",
      "Range\n",
      "Range\n",
      "Unsqueeze\n",
      "Conv\n",
      "Add\n",
      "Add\n",
      "Concat\n",
      "Sigmoid\n",
      "ConstantOfShape\n",
      "Shape\n",
      "Shape\n",
      "Reshape\n",
      "Reshape\n",
      "Mul\n",
      "Add\n",
      "Concat\n",
      "Conv\n",
      "Expand\n",
      "Expand\n",
      "Sigmoid\n",
      "Unsqueeze\n",
      "Unsqueeze\n",
      "Mul\n",
      "Concat\n",
      "Add\n",
      "Reshape\n",
      "Concat\n",
      "Conv\n",
      "Sigmoid\n",
      "Mul\n",
      "Concat\n",
      "Conv\n",
      "Sigmoid\n",
      "Mul\n",
      "Conv\n",
      "Conv\n",
      "Sigmoid\n",
      "Sigmoid\n",
      "Mul\n",
      "Mul\n",
      "Conv\n",
      "Conv\n",
      "Sigmoid\n",
      "Sigmoid\n",
      "Mul\n",
      "Mul\n",
      "Conv\n",
      "Conv\n",
      "Sigmoid\n",
      "Mul\n",
      "Conv\n",
      "Sigmoid\n",
      "Mul\n",
      "Conv\n",
      "Concat\n",
      "Reshape\n",
      "Shape\n",
      "Concat\n",
      "Gather\n",
      "Gather\n",
      "Cast\n",
      "Cast\n",
      "Mul\n",
      "Split\n",
      "Range\n",
      "Range\n",
      "Unsqueeze\n",
      "Shape\n",
      "Sigmoid\n",
      "Add\n",
      "Add\n",
      "Concat\n",
      "Gather\n",
      "Gather\n",
      "ConstantOfShape\n",
      "Unsqueeze\n",
      "Unsqueeze\n",
      "Shape\n",
      "Shape\n",
      "Reshape\n",
      "Reshape\n",
      "Add\n",
      "Concat\n",
      "Concat\n",
      "Concat\n",
      "Concat\n",
      "Reshape\n",
      "Expand\n",
      "Expand\n",
      "Transpose\n",
      "Transpose\n",
      "Unsqueeze\n",
      "Unsqueeze\n",
      "Softmax\n",
      "Concat\n",
      "Conv\n",
      "Reshape\n",
      "Reshape\n",
      "Concat\n",
      "Slice\n",
      "Slice\n",
      "Transpose\n",
      "Unsqueeze\n",
      "Sub\n",
      "Add\n",
      "Add\n",
      "Sub\n",
      "Div\n",
      "Concat\n",
      "Mul\n",
      "Concat\n"
     ]
    }
   ],
   "source": [
    "######################\n",
    "#### CHECK THE ONNX OP\n",
    "######################\n",
    "import onnx\n",
    "\n",
    "model = onnx.load(f\"runs/{MODEL_NAME}_bowl_fountain_finetune/weights/best.onnx\")\n",
    "for node in model.graph.node:\n",
    "    print(node.op_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ac40ce9d-a9e5-46dc-a43a-2b9ed7ba4741",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'yolo11n_bowl_fountain_finetune.onnx'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "shutil.copy2(f\"runs/{MODEL_NAME}_bowl_fountain_finetune/weights/best.onnx\", f\"{MODEL_NAME}_bowl_fountain_finetune.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69cdb895-40b3-4949-bf75-c68eaaa78f84",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
